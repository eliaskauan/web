# Sistema de Web Scraping Parts Unlimited

Sistema completo de web scraping para extrair informa√ß√µes de produtos do site Parts Unlimited baseado em arquivo CSV.

## üéØ Funcionalidades

- **Processamento CSV**: L√™ arquivo CSV e busca produtos baseado na coluna "termo"
- **Busca Inteligente**: Utiliza o campo de busca da p√°gina principal para realizar pesquisas naturais
- **Extra√ß√£o Completa**: Extrai nome, pre√ßo, SKU, imagens, especifica√ß√µes e mais
- **Anti-Detec√ß√£o**: M√∫ltiplas estrat√©gias para evitar bloqueios (user-agents, delays, etc.)
- **Salvamento JSON**: Organiza dados extra√≠dos em arquivos JSON estruturados
- **Tratamento de Erros**: Sistema robusto com retry autom√°tico e logging detalhado
- **Progresso Incremental**: Salva progresso automaticamente para retomar execu√ß√£o

## üì¶ Instala√ß√£o

1. **Clone ou baixe os arquivos do projeto**

2. **Instale as depend√™ncias:**
```bash
pip install -r requirements.txt
```

3. **Instale os navegadores do Playwright:**
```bash
playwright install chromium
```

## üöÄ Uso

### **Arquivo Principal: `main_scraper.py`**

### Uso B√°sico
```bash
python main_scraper.py --excel arquivo_entrada.xlsx
```

### Uso Avan√ßado
```bash
# Especificar diret√≥rio de sa√≠da
python main_scraper.py --excel produtos.xlsx --output resultados/

# Modo debug com navegador vis√≠vel
python main_scraper.py --excel dados.xlsx --debug --no-headless

# Ver ajuda completa
python main_scraper.py --help
```

### Outros arquivos dispon√≠veis:
- `main_scraper_simples.py` - Vers√£o de demonstra√ß√£o (usa config_scraper.json)
- `scraper_parts_unlimited.py` - Sistema para arquivos CSV

## üìÅ Estrutura do Projeto

```
web-crawler/
‚îú‚îÄ‚îÄ main_scraper.py           # üöÄ ARQUIVO PRINCIPAL - Sistema completo com Excel
‚îú‚îÄ‚îÄ main_scraper_simples.py   # Vers√£o de demonstra√ß√£o
‚îú‚îÄ‚îÄ scraper_parts_unlimited.py # Sistema para arquivos CSV
‚îú‚îÄ‚îÄ parts_unlimited_scraper.py # Classe de scraping avan√ßada
‚îú‚îÄ‚îÄ web_scraper.py            # Classe de web scraping b√°sica
‚îú‚îÄ‚îÄ csv_processor.py          # Processamento de CSV
‚îú‚îÄ‚îÄ excel_processor.py        # Processamento de Excel
‚îú‚îÄ‚îÄ data_saver.py            # Salvamento de dados
‚îú‚îÄ‚îÄ config.py                # Configura√ß√µes para CSV
‚îú‚îÄ‚îÄ config_scraper.json      # Configura√ß√µes para demonstra√ß√£o
‚îú‚îÄ‚îÄ requirements.txt         # Depend√™ncias
‚îú‚îÄ‚îÄ README.md               # Documenta√ß√£o
‚îî‚îÄ‚îÄ saida/                  # Diret√≥rio de arquivos JSON (criado automaticamente)
```

## üìÑ Formato do CSV de Entrada

O arquivo CSV deve conter pelo menos uma coluna chamada `termo`:

```csv
termo,resultado
ABC123,
XYZ789,
DEF456,
```

- **termo**: C√≥digo ou termo a ser buscado
- **resultado**: Coluna atualizada automaticamente com status (OK, nao-encontrado, erro)

## üìä Sa√≠da do Sistema

### 1. CSV Atualizado
O arquivo CSV original √© atualizado com a coluna "resultado":
```csv
termo,resultado
ABC123,OK
XYZ789,nao-encontrado
DEF456,erro
```

### 2. Arquivos JSON
Para cada produto encontrado, um arquivo JSON √© criado em `saida/`:

```json
{
  "metadados": {
    "timestamp": "2024-01-15T10:30:00",
    "versao_scraper": "1.0.0",
    "arquivo_origem": "ABC123"
  },
  "produto": {
    "url": "https://www.parts-unlimited.com/product/abc123",
    "nome": "Nome do Produto",
    "preco": "$99.99",
    "sku": "ABC123",
    "imagens": ["https://example.com/image1.jpg"],
    "descricao": "Descri√ß√£o do produto...",
    "especificacoes": {
      "Material": "Alum√≠nio",
      "Peso": "2.5 kg"
    },
    "disponibilidade": "Em estoque",
    "categoria": "Categoria > Subcategoria"
  }
}
```

### 3. Log Detalhado
Arquivo `scraper.log` com informa√ß√µes detalhadas da execu√ß√£o.

## ‚öôÔ∏è Configura√ß√µes

O arquivo `config.py` permite ajustar:

- **Delays**: Tempo entre requisi√ß√µes (2-8 segundos por padr√£o)
- **Timeouts**: Tempo limite para carregamento de p√°ginas
- **User Agents**: Lista de user agents rotativos
- **Seletores CSS**: Seletores para extrair dados do site
- **Retries**: N√∫mero m√°ximo de tentativas por produto

## üõ°Ô∏è Estrat√©gias Anti-Detec√ß√£o

- **User-agents rotativos**: Simula diferentes navegadores
- **Headers HTTP variados**: Headers realistas e convincentes
- **Delays aleat√≥rios**: Entre 2-8 segundos por requisi√ß√£o
- **Simula√ß√£o humana**: Scroll e movimentos de mouse
- **Rate limiting**: Controle inteligente de velocidade
- **Retry autom√°tico**: Recupera√ß√£o de falhas tempor√°rias

## üìà Estat√≠sticas

O sistema exibe estat√≠sticas completas ao final:

```
=== ESTAT√çSTICAS FINAIS ===
Total de termos: 100
Processados: 95
Encontrados: 78
N√£o encontrados: 12
Erros: 5
Taxa de sucesso: 82.1%
Dura√ß√£o: 0:15:30
```

## üîß Solu√ß√£o de Problemas

### Erro: "Arquivo CSV n√£o encontrado"
- Verifique se o caminho do arquivo est√° correto
- Use caminho absoluto se necess√°rio

### Erro: "Coluna 'termo' n√£o encontrada"
- Certifique-se que o CSV tem uma coluna chamada "termo"
- Verifique a codifica√ß√£o do arquivo (deve ser UTF-8)

### Navegador n√£o abre ou trava
- Tente executar com `--no-headless` para ver o navegador
- Verifique se o Playwright foi instalado corretamente
- Execute `playwright install chromium`

### Site est√° bloqueando requisi√ß√µes
- Aumente os delays em `config.py`
- Verifique se h√° captchas ou medidas anti-bot
- Use `--debug` para ver logs detalhados

### Produtos n√£o s√£o encontrados
- Verifique se os termos de busca est√£o corretos
- Use `--debug` para ver URLs de busca
- Os seletores CSS podem precisar de ajuste

## üìù Requisitos do Sistema

- **Python**: 3.8 ou superior
- **Sistema**: Windows, macOS ou Linux
- **Mem√≥ria**: M√≠nimo 4GB RAM recomendado
- **Espa√ßo**: ~500MB para Playwright + dados

## ü§ù Contribui√ß√£o

Este √© um projeto educacional. Para melhorias:

1. Ajuste os seletores CSS conforme mudan√ßas no site
2. Adicione novos campos de extra√ß√£o conforme necess√°rio
3. Otimize estrat√©gias anti-detec√ß√£o baseado no comportamento do site

## ‚öñÔ∏è Considera√ß√µes Legais

- Respeite sempre os termos de uso do site
- Use delays apropriados para n√£o sobrecarregar o servidor
- Este c√≥digo √© para fins educacionais e de pesquisa
- Verifique a legalidade do web scraping em sua jurisdi√ß√£o

## üÜî Vers√£o

**Parts Unlimited Scraper v1.0.0**

Desenvolvido em Python com Playwright para m√°xima compatibilidade e robustez.